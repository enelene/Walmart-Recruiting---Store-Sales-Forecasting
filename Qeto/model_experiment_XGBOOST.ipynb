{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-09T00:40:04.021084Z",
     "start_time": "2025-07-09T00:40:03.466767Z"
    }
   },
   "source": [
    "import mlflow.xgboost\n",
    "import warnings\n",
    "import dagshub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "dagshub.init(repo_owner='qetibakh', repo_name='Final', mlflow=True)\n",
    "mlflow.set_tracking_uri('https://dagshub.com/qetibakh/Final.mlflow')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"qetibakh/Final\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"qetibakh/Final\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Repository qetibakh/Final initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository qetibakh/Final initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T00:40:33.904660Z",
     "start_time": "2025-07-09T00:40:32.771497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./data/Clean_training.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ],
   "id": "f5e22bcfb1409871",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T00:40:34.287399Z",
     "start_time": "2025-07-09T00:40:34.251562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_col = 'Target'\n",
    "feature_cols = [col for col in df.columns if col not in [target_col, 'Date']]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]"
   ],
   "id": "6570c05d4f519d01",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T00:40:35.529015Z",
     "start_time": "2025-07-09T00:40:35.419900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_cutoff = df['Date'].max() - pd.DateOffset(months=6)\n",
    "val_cutoff = df['Date'].max() - pd.DateOffset(months=12)\n",
    "\n",
    "train_mask = df['Date'] <= val_cutoff\n",
    "val_mask = (df['Date'] > val_cutoff) & (df['Date'] <= test_cutoff)\n",
    "test_mask = df['Date'] > test_cutoff\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_val, y_val = X[val_mask], y[val_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "# Create DataFrame versions for the WMAE function\n",
    "train_df = df[train_mask]\n",
    "val_df = df[val_mask]\n",
    "test_df = df[test_mask]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ],
   "id": "f5c49c7aea51aaea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 264220\n",
      "Validation samples: 77493\n",
      "Test samples: 79857\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T00:40:49.765001Z",
     "start_time": "2025-07-09T00:40:49.762032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def WMAE(dataset, real, predicted):\n",
    "    # The 'IsHoliday' column must be present in the feature set\n",
    "    weights = dataset['IsHoliday'].apply(lambda x: 5 if x else 1)\n",
    "    return np.round(np.sum(weights * abs(real - predicted)) / (np.sum(weights)), 2)"
   ],
   "id": "f6be770589d66da3",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T00:48:18.986210Z",
     "start_time": "2025-07-09T00:48:18.979197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def comprehensive_model_evaluation(name, model, X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                                 train_df, val_df, test_df):\n",
    "    \"\"\"\n",
    "    A robust model evaluation function with MLflow logging and visualizations.\n",
    "    \"\"\"\n",
    "    # This is without hyperparameter optimization\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{name.strip()}_run\"):\n",
    "        # Fit model and make predictions\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'val_rmse': np.sqrt(mean_squared_error(y_val, y_pred_val)),\n",
    "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'train_wmae': WMAE(train_df, y_train, y_pred_train),\n",
    "            'val_wmae': WMAE(val_df, y_val, y_pred_val),\n",
    "            'test_wmae': WMAE(test_df, y_test, y_pred_test),\n",
    "            'train_r2': r2_score(y_train, y_pred_train),\n",
    "            'val_r2': r2_score(y_val, y_pred_val),\n",
    "            'test_r2': r2_score(y_test, y_pred_test)\n",
    "        }\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Log model parameters\n",
    "        if hasattr(model, 'get_params'):\n",
    "            mlflow.log_params(model.get_params())\n",
    "\n",
    "        # Log the model itself\n",
    "        model_name = name.strip().lower()\n",
    "        if 'xgboost' in model_name:\n",
    "            mlflow.xgboost.log_model(model, f\"{name.strip()}_model\")\n",
    "        elif 'lgbm' in model_name:\n",
    "            mlflow.lightgbm.log_model(model, f\"{name.strip()}_model\")\n",
    "        elif 'catboost' in model_name:\n",
    "            mlflow.catboost.log_model(model, f\"{name.strip()}_model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, f\"{name.strip()}_model\")\n",
    "\n",
    "        # --- NEW & SIMPLIFIED PREDICTION DATAFRAME ---\n",
    "        # This new method is much cleaner and avoids the length mismatch error.\n",
    "        train_preds_df = pd.DataFrame({'actual': y_train, 'predicted': y_pred_train, 'origin': 'train'})\n",
    "        val_preds_df = pd.DataFrame({'actual': y_val, 'predicted': y_pred_val, 'origin': 'validation'})\n",
    "        test_preds_df = pd.DataFrame({'actual': y_test, 'predicted': y_pred_test, 'origin': 'test'})\n",
    "\n",
    "        predictions_df = pd.concat([train_preds_df, val_preds_df, test_preds_df])\n",
    "        predictions_df.to_csv(f\"{name.strip()}_predictions.csv\", index=False)\n",
    "        mlflow.log_artifact(f\"{name.strip()}_predictions.csv\")\n",
    "\n",
    "        # --- NEW VISUALIZATION ARTIFACT ---\n",
    "        # Create and log a scatter plot of predictions vs actuals\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.scatterplot(data=predictions_df, x='actual', y='predicted', hue='origin', alpha=0.5)\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', lw=2)\n",
    "        plt.title(f'{name.strip()} - Actual vs. Predicted')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.grid(True)\n",
    "        plot_path = f\"{name.strip()}_prediction_plot.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close() # Close the plot to avoid displaying it in the notebook\n",
    "        mlflow.log_artifact(plot_path)\n",
    "\n",
    "        print(f\"{name} - Val RMSE: {metrics['val_rmse']:.4f}, Val WMAE: {metrics['val_wmae']:.2f}, Test RMSE: {metrics['test_rmse']:.4f}, Test WMAE: {metrics['test_wmae']:.2f}\")\n",
    "\n",
    "        return {\n",
    "            'model_name': name.strip(), 'val_rmse': metrics['val_rmse'], 'test_rmse': metrics['test_rmse'],\n",
    "            'val_wmae': metrics['val_wmae'], 'test_wmae': metrics['test_wmae'], 'val_r2': metrics['val_r2'], 'test_r2': metrics['test_r2']\n",
    "        }\n"
   ],
   "id": "af9611940dabd37f",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T01:07:25.488280Z",
     "start_time": "2025-07-09T00:48:23.782251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.set_experiment(\"testing_treebased_models\")\n",
    "\n",
    "models = {\n",
    "    'LGBM': lgb.LGBMRegressor(random_state=0, verbose=-1),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=0, objective='reg:squarederror'),\n",
    "    'CatBoost': cb.CatBoostRegressor(random_state=0, verbose=False),\n",
    "    'HGBR': HistGradientBoostingRegressor(random_state=0),\n",
    "    'ExtraTrees': ExtraTreesRegressor(bootstrap=True, random_state=0),\n",
    "    'RandomForest': RandomForestRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "print(\"\\nStarting comprehensive model evaluation with MLflow logging...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    result = comprehensive_model_evaluation(\n",
    "        name, model,\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        X_test, y_test,\n",
    "        train_df, val_df, test_df\n",
    "    )\n",
    "    results.append(result)"
   ],
   "id": "5787525921fb00b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting comprehensive model evaluation with MLflow logging...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/09 04:48:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM - Val RMSE: 10671.3733, Val WMAE: 6396.49, Test RMSE: 8699.8937, Test WMAE: 5638.97\n",
      "🏃 View run LGBM_run at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3/runs/34452289960e4ce49e3fb1489ddaf381\n",
      "🧪 View experiment at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/09 04:48:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Val RMSE: 9451.0222, Val WMAE: 5281.80, Test RMSE: 7527.1744, Test WMAE: 4609.96\n",
      "🏃 View run XGBoost_run at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3/runs/983e007030e545fcbde8b152633c7230\n",
      "🧪 View experiment at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/09 04:49:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost - Val RMSE: 9690.5881, Val WMAE: 5684.23, Test RMSE: 7609.6186, Test WMAE: 4880.81\n",
      "🏃 View run CatBoost_run at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3/runs/66e64764101d4e4498efa82508b409bb\n",
      "🧪 View experiment at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/09 04:49:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGBR - Val RMSE: 10676.7914, Val WMAE: 6341.99, Test RMSE: 8598.8361, Test WMAE: 5450.53\n",
      "🏃 View run HGBR_run at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3/runs/c04e478a0c17460085957da4186d2a15\n",
      "🧪 View experiment at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/09 04:51:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees - Val RMSE: 7694.9019, Val WMAE: 3635.90, Test RMSE: 6676.5239, Test WMAE: 3477.52\n",
      "🏃 View run ExtraTrees_run at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3/runs/d355171eaaaa40c4b7538179dc1695fd\n",
      "🧪 View experiment at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/09 04:58:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Val RMSE: 11074.7647, Val WMAE: 4172.74, Test RMSE: 9389.3332, Test WMAE: 4365.94\n",
      "🏃 View run RandomForest_run at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3/runs/fde6ebae905649b18ef7abecba81d0ec\n",
      "🧪 View experiment at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T01:07:27.493781Z",
     "start_time": "2025-07-09T01:07:25.555430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if results:\n",
    "    results_df = pd.DataFrame(results).sort_values('val_rmse')\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    with mlflow.start_run(run_name=\"model_comparison_summary\"):\n",
    "        results_df.to_csv('model_comparison_results.csv', index=False)\n",
    "        mlflow.log_artifact('model_comparison_results.csv')\n",
    "\n",
    "        best_model = results_df.iloc[0]\n",
    "        mlflow.log_metrics({\n",
    "            'best_model_val_rmse': best_model['val_rmse'],\n",
    "            'best_model_test_rmse': best_model['test_rmse'],\n",
    "            'best_model_val_wmae': best_model['val_wmae'],\n",
    "            'best_model_test_wmae': best_model['test_wmae']\n",
    "        })\n",
    "        mlflow.log_param('best_model_name', best_model['model_name'])\n",
    "\n",
    "        print(f\"\\nBest Model: {best_model['model_name']}\")\n",
    "        print(f\"Best Validation RMSE: {best_model['val_rmse']:.4f}\")"
   ],
   "id": "8d258099535498eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "  model_name     val_rmse   test_rmse  val_wmae  test_wmae   val_r2  test_r2\n",
      "  ExtraTrees  7694.901917 6676.523901   3635.90    3477.52 0.900333 0.907801\n",
      "     XGBoost  9451.022227 7527.174359   5281.80    4609.96 0.849650 0.882810\n",
      "    CatBoost  9690.588144 7609.618596   5684.23    4880.81 0.841931 0.880229\n",
      "        LGBM 10671.373288 8699.893697   6396.49    5638.97 0.808316 0.843450\n",
      "        HGBR 10676.791448 8598.836122   6341.99    5450.53 0.808121 0.847066\n",
      "RandomForest 11074.764725 9389.333235   4172.74    4365.94 0.793550 0.817654\n",
      "\n",
      "Best Model: ExtraTrees\n",
      "Best Validation RMSE: 7694.9019\n",
      "🏃 View run model_comparison_summary at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3/runs/b7c8de07039b46bc9ff1fcb1830d072d\n",
      "🧪 View experiment at: https://dagshub.com/qetibakh/Final.mlflow/#/experiments/3\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "რა არის გასაკეთებელი:\n",
    "1. ჰიპერპარამეტრების დამატება\n",
    "2. აუთლაიერების ამოგდება\n",
    "3. უკეთესი featureების გამოყვანა https://www.kaggle.com/code/maxdiazbattan/wallmart-sales-top-3-eda-feature-engineering#-3.1-|-Sales-analysis\n",
    "4. featureბის შერჩევა"
   ],
   "id": "f504bc5273ee9116"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
